Object.defineProperty(exports, '__esModule', { value: true });

var Arr = require('effect/Array');
var Function = require('effect/Function');
var Micro = require('effect/Micro');
var Option = require('effect/Option');
var shared = require('@uploadthing/shared');
var stdEnv = require('std-env');

function _interopNamespace(e) {
  if (e && e.__esModule) return e;
  var n = Object.create(null);
  if (e) {
    Object.keys(e).forEach(function (k) {
      if (k !== 'default') {
        var d = Object.getOwnPropertyDescriptor(e, k);
        Object.defineProperty(n, k, d.get ? d : {
          enumerable: true,
          get: function () { return e[k]; }
        });
      }
    });
  }
  n.default = e;
  return n;
}

var Arr__namespace = /*#__PURE__*/_interopNamespace(Arr);
var Micro__namespace = /*#__PURE__*/_interopNamespace(Micro);
var Option__namespace = /*#__PURE__*/_interopNamespace(Option);

var version$1 = "6.13.3";

const uploadMultipartWithProgress = (file, presigned, opts)=>Micro__namespace.gen(function*() {
        let uploadedBytes = 0;
        const etags = yield* Micro__namespace.forEach(presigned.urls, (url, index)=>{
            const offset = presigned.chunkSize * index;
            const end = Math.min(offset + presigned.chunkSize, file.size);
            const chunk = file.slice(offset, end);
            return uploadPart({
                url,
                chunk: chunk,
                contentDisposition: presigned.contentDisposition,
                fileType: file.type,
                fileName: file.name,
                onProgress: (delta)=>{
                    uploadedBytes += delta;
                    const percent = uploadedBytes / file.size * 100;
                    opts.onUploadProgress?.({
                        file: file.name,
                        progress: percent
                    });
                }
            }).pipe(Micro__namespace.map((tag)=>({
                    tag,
                    partNumber: index + 1
                })), Micro__namespace.retry({
                while: (error)=>error instanceof shared.RetryError,
                times: stdEnv.isTest ? 3 : 10,
                schedule: shared.exponentialDelay()
            }));
        }, {
            concurrency: "inherit"
        }).pipe(Micro__namespace.tapError((error)=>opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: presigned.uploadId,
                fileName: file.name,
                storageProviderError: String(error)
            })));
        // Tell the server that the upload is complete
        yield* opts.reportEventToUT("multipart-complete", {
            uploadId: presigned.uploadId,
            fileKey: presigned.key,
            etags
        });
    });
const uploadPart = (opts)=>Micro__namespace.async((resume)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("PUT", opts.url, true);
        xhr.setRequestHeader("Content-Type", opts.fileType);
        xhr.setRequestHeader("Content-Disposition", shared.contentDisposition(opts.contentDisposition, opts.fileName));
        xhr.addEventListener("load", ()=>{
            const etag = xhr.getResponseHeader("Etag");
            if (xhr.status >= 200 && xhr.status <= 299 && etag) {
                return resume(Micro__namespace.succeed(etag));
            }
            return resume(Micro__namespace.fail(new shared.RetryError()));
        });
        xhr.addEventListener("error", ()=>resume(Micro__namespace.fail(new shared.RetryError())));
        let lastProgress = 0;
        xhr.upload.addEventListener("progress", (e)=>{
            const delta = e.loaded - lastProgress;
            lastProgress += delta;
            opts.onProgress(delta);
        });
        xhr.send(opts.chunk);
        // Cleanup function that runs on interruption
        return Micro__namespace.sync(()=>xhr.abort());
    });

const uploadPresignedPostWithProgress = (file, presigned, opts)=>Micro__namespace.async((resume)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("POST", presigned.url);
        xhr.setRequestHeader("Accept", "application/xml");
        xhr.upload.addEventListener("progress", ({ loaded, total })=>{
            opts.onUploadProgress?.({
                file: file.name,
                progress: loaded / total * 100
            });
        });
        xhr.addEventListener("load", ()=>resume(xhr.status >= 200 && xhr.status < 300 ? Micro__namespace.succeed(null) : opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: null,
                fileName: file.name,
                storageProviderError: xhr.responseText
            })));
        xhr.addEventListener("error", ()=>resume(opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: null,
                fileName: file.name
            })));
        const formData = new FormData();
        Object.entries(presigned.fields).forEach(([k, v])=>formData.append(k, v));
        formData.append("file", file); // File data **MUST GO LAST**
        xhr.send(formData);
        return Micro__namespace.sync(()=>{
            xhr.abort();
        });
    });

const maybeParseResponseXML = (maybeXml)=>{
    const codeMatch = maybeXml.match(/<Code>(.*?)<\/Code>/s);
    const messageMatch = maybeXml.match(/<Message>(.*?)<\/Message>/s);
    const code = codeMatch?.[1];
    const message = messageMatch?.[1];
    if (!code || !message) return null;
    return {
        code: s3CodeToUploadThingCode[code] ?? DEFAULT_ERROR_CODE,
        message
    };
};
/**
 * Map S3 error codes to UploadThing error codes
 *
 * This is a subset of the S3 error codes, based on what seemed most likely to
 * occur in uploadthing. For a full list of S3 error codes, see:
 * https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html
 */ const DEFAULT_ERROR_CODE = "UPLOAD_FAILED";
const s3CodeToUploadThingCode = {
    AccessDenied: "FORBIDDEN",
    EntityTooSmall: "TOO_SMALL",
    EntityTooLarge: "TOO_LARGE",
    ExpiredToken: "FORBIDDEN",
    IncorrectNumberOfFilesInPostRequest: "TOO_MANY_FILES",
    InternalError: "INTERNAL_SERVER_ERROR",
    KeyTooLongError: "KEY_TOO_LONG",
    MaxMessageLengthExceeded: "TOO_LARGE"
};

const createAPIRequestUrl = (config)=>{
    const url = new URL(config.url);
    const queryParams = new URLSearchParams(url.search);
    queryParams.set("actionType", config.actionType);
    queryParams.set("slug", config.slug);
    url.search = queryParams.toString();
    return url;
};
/**
 * Creates a "client" for reporting events to the UploadThing server via the user's API endpoint.
 * Events are handled in "./handler.ts starting at L112"
 */ const createUTReporter = (cfg)=>(type, payload)=>Micro__namespace.gen(function*() {
            const url = createAPIRequestUrl({
                url: cfg.url,
                slug: cfg.endpoint,
                actionType: type
            });
            let headers = typeof cfg.headers === "function" ? cfg.headers() : cfg.headers;
            if (headers instanceof Promise) {
                headers = yield* Micro__namespace.promise(()=>headers);
            }
            const response = yield* shared.fetchEff(url, {
                method: "POST",
                body: JSON.stringify(payload),
                headers: {
                    "Content-Type": "application/json",
                    "x-uploadthing-package": cfg.package,
                    "x-uploadthing-version": version$1,
                    ...headers
                }
            }).pipe(Micro__namespace.andThen(shared.parseResponseJson), /**
         * We don't _need_ to validate the response here, just cast it for now.
         * As of now, @effect/schema includes quite a few bytes we cut out by this...
         * We have "strong typing" on the backend that ensures the shape should match.
         */ Micro__namespace.map(Function.unsafeCoerce), Micro__namespace.catchTag("FetchError", (e)=>Micro__namespace.fail(new shared.UploadThingError({
                    code: "INTERNAL_CLIENT_ERROR",
                    message: `Failed to report event "${type}" to UploadThing server`,
                    cause: e
                }))), Micro__namespace.catchTag("BadRequestError", (e)=>Micro__namespace.fail(new shared.UploadThingError({
                    code: shared.getErrorTypeFromStatusCode(e.status),
                    message: e.getMessage(),
                    cause: e.json
                }))), Micro__namespace.catchTag("InvalidJson", (e)=>Micro__namespace.fail(new shared.UploadThingError({
                    code: "INTERNAL_CLIENT_ERROR",
                    message: "Failed to parse response from UploadThing server",
                    cause: e
                }))));
            switch(type){
                case "failure":
                    {
                        // why isn't this narrowed automatically?
                        const p = payload;
                        const parsed = maybeParseResponseXML(p.storageProviderError ?? "");
                        if (parsed?.message) {
                            return yield* new shared.UploadThingError({
                                code: parsed.code,
                                message: parsed.message
                            });
                        } else {
                            return yield* new shared.UploadThingError({
                                code: "UPLOAD_FAILED",
                                message: `Failed to upload file ${p.fileName} to S3`,
                                cause: p.storageProviderError
                            });
                        }
                    }
            }
            return response;
        });

const version = version$1;
/**
 * Validate that a file is of a valid type given a route config
 * @public
 */ const isValidFileType = (file, routeConfig)=>Micro__namespace.runSync(shared.getTypeFromFileName(file.name, shared.objectKeys(routeConfig)).pipe(Micro__namespace.map((type)=>file.type.includes(type)), Micro__namespace.orElseSucceed(()=>false)));
/**
 * Validate that a file is of a valid size given a route config
 * @public
 */ const isValidFileSize = (file, routeConfig)=>Micro__namespace.runSync(shared.getTypeFromFileName(file.name, shared.objectKeys(routeConfig)).pipe(Micro__namespace.flatMap((type)=>shared.fileSizeToBytes(routeConfig[type].maxFileSize)), Micro__namespace.map((maxFileSize)=>file.size <= maxFileSize), Micro__namespace.orElseSucceed(()=>false)));
/**
 * Generate a typed uploader for a given FileRouter
 * @public
 */ const genUploader = (initOpts)=>{
    return (endpoint, opts)=>uploadFilesInternal(endpoint, {
            ...opts,
            url: shared.resolveMaybeUrlArg(initOpts?.url),
            package: initOpts.package,
            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
            input: opts.input
        }).pipe(Micro__namespace.provideService(shared.FetchContext, {
            fetch: globalThis.fetch.bind(globalThis),
            baseHeaders: {
                "x-uploadthing-version": version$1,
                "x-uploadthing-api-key": undefined,
                "x-uploadthing-fe-package": initOpts.package,
                "x-uploadthing-be-adapter": undefined
            }
        }), (e)=>Micro__namespace.runPromiseExit(e, opts.signal ? {
                signal: opts.signal
            } : {})).then((exit)=>{
            if (exit._tag === "Right") {
                return exit.right;
            } else if (exit.left._tag === "Interrupt") {
                throw new shared.UploadAbortedError();
            }
            throw Micro__namespace.causeSquash(exit.left);
        });
};
const uploadFilesInternal = (endpoint, opts)=>{
    // classic service right here
    const reportEventToUT = createUTReporter({
        endpoint: String(endpoint),
        package: opts.package,
        url: shared.resolveMaybeUrlArg(opts.url),
        headers: opts.headers
    });
    return reportEventToUT("upload", {
        input: "input" in opts ? opts.input : null,
        files: opts.files.map((f)=>({
                name: f.name,
                size: f.size,
                type: f.type
            }))
    }).pipe(Micro__namespace.flatMap((responses)=>Micro__namespace.forEach(responses, (presigned)=>uploadFile(String(endpoint), {
                ...opts,
                reportEventToUT
            }, presigned).pipe(Micro__namespace.onInterrupt(reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: "uploadId" in presigned ? presigned.uploadId : null,
                fileName: presigned.fileName
            }).pipe(Micro__namespace.ignore))), {
            concurrency: 6
        })));
};
const isPollingResponse = (input)=>{
    if (!shared.isObject(input)) return false;
    if (input.status === "done") return "callbackData" in input;
    return input.status === "still waiting";
};
const isPollingDone = (input)=>{
    return input.status === "done";
};
const uploadFile = (slug, opts, presigned)=>Arr__namespace.findFirst(opts.files, (file)=>file.name === presigned.fileName).pipe(Micro__namespace.fromOption, Micro__namespace.mapError(()=>{
        // eslint-disable-next-line no-console
        console.error("No file found for presigned URL", presigned);
        return new shared.UploadThingError({
            code: "NOT_FOUND",
            message: "No file found for presigned URL",
            cause: `Expected file with name ${presigned.fileName} but got '${opts.files.join(",")}'`
        });
    }), Micro__namespace.tap((file)=>opts.onUploadBegin?.({
            file: file.name
        })), Micro__namespace.tap((file)=>"urls" in presigned ? uploadMultipartWithProgress(file, presigned, opts) : uploadPresignedPostWithProgress(file, presigned, opts)), Micro__namespace.zip(shared.fetchEff(presigned.pollingUrl, {
        headers: {
            authorization: presigned.pollingJwt
        }
    }).pipe(Micro__namespace.flatMap(shared.parseResponseJson), Micro__namespace.catchTag("BadRequestError", (e)=>Micro__namespace.fail(new shared.UploadThingError({
            code: shared.getErrorTypeFromStatusCode(e.status),
            message: e.message,
            cause: e
        }))), Micro__namespace.filterOrFailCause(isPollingResponse, (_)=>Micro__namespace.causeDie("received a non PollingResponse from the polling endpoint")), Micro__namespace.filterOrFail(isPollingDone, ()=>new shared.RetryError()), Micro__namespace.map(({ callbackData })=>callbackData), Micro__namespace.retry({
        while: (res)=>res._tag === "RetryError",
        schedule: shared.exponentialDelay()
    }), Micro__namespace.when(()=>!opts.skipPolling), Micro__namespace.map(Option__namespace.getOrNull), Micro__namespace.map(Function.unsafeCoerce))), Micro__namespace.map(([file, serverData])=>({
            name: file.name,
            size: file.size,
            key: presigned.key,
            serverData,
            url: presigned.fileUrl,
            appUrl: presigned.appUrl,
            customId: presigned.customId,
            type: file.type
        })));

Object.defineProperty(exports, "UploadAbortedError", {
  enumerable: true,
  get: function () { return shared.UploadAbortedError; }
});
Object.defineProperty(exports, "generateClientDropzoneAccept", {
  enumerable: true,
  get: function () { return shared.generateClientDropzoneAccept; }
});
Object.defineProperty(exports, "generateMimeTypes", {
  enumerable: true,
  get: function () { return shared.generateMimeTypes; }
});
Object.defineProperty(exports, "generatePermittedFileTypes", {
  enumerable: true,
  get: function () { return shared.generatePermittedFileTypes; }
});
exports.genUploader = genUploader;
exports.isValidFileSize = isValidFileSize;
exports.isValidFileType = isValidFileType;
exports.version = version;
