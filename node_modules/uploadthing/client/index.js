import * as Arr from 'effect/Array';
import { unsafeCoerce } from 'effect/Function';
import * as Micro from 'effect/Micro';
import * as Option from 'effect/Option';
import { RetryError, exponentialDelay, contentDisposition, fetchEff, parseResponseJson, UploadThingError, getErrorTypeFromStatusCode, getTypeFromFileName, objectKeys, fileSizeToBytes, resolveMaybeUrlArg, FetchContext, UploadAbortedError, isObject } from '@uploadthing/shared';
export { UploadAbortedError, generateClientDropzoneAccept, generateMimeTypes, generatePermittedFileTypes } from '@uploadthing/shared';
import { isTest } from 'std-env';

var version$1 = "6.13.3";

const uploadMultipartWithProgress = (file, presigned, opts)=>Micro.gen(function*() {
        let uploadedBytes = 0;
        const etags = yield* Micro.forEach(presigned.urls, (url, index)=>{
            const offset = presigned.chunkSize * index;
            const end = Math.min(offset + presigned.chunkSize, file.size);
            const chunk = file.slice(offset, end);
            return uploadPart({
                url,
                chunk: chunk,
                contentDisposition: presigned.contentDisposition,
                fileType: file.type,
                fileName: file.name,
                onProgress: (delta)=>{
                    uploadedBytes += delta;
                    const percent = uploadedBytes / file.size * 100;
                    opts.onUploadProgress?.({
                        file: file.name,
                        progress: percent
                    });
                }
            }).pipe(Micro.map((tag)=>({
                    tag,
                    partNumber: index + 1
                })), Micro.retry({
                while: (error)=>error instanceof RetryError,
                times: isTest ? 3 : 10,
                schedule: exponentialDelay()
            }));
        }, {
            concurrency: "inherit"
        }).pipe(Micro.tapError((error)=>opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: presigned.uploadId,
                fileName: file.name,
                storageProviderError: String(error)
            })));
        // Tell the server that the upload is complete
        yield* opts.reportEventToUT("multipart-complete", {
            uploadId: presigned.uploadId,
            fileKey: presigned.key,
            etags
        });
    });
const uploadPart = (opts)=>Micro.async((resume)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("PUT", opts.url, true);
        xhr.setRequestHeader("Content-Type", opts.fileType);
        xhr.setRequestHeader("Content-Disposition", contentDisposition(opts.contentDisposition, opts.fileName));
        xhr.addEventListener("load", ()=>{
            const etag = xhr.getResponseHeader("Etag");
            if (xhr.status >= 200 && xhr.status <= 299 && etag) {
                return resume(Micro.succeed(etag));
            }
            return resume(Micro.fail(new RetryError()));
        });
        xhr.addEventListener("error", ()=>resume(Micro.fail(new RetryError())));
        let lastProgress = 0;
        xhr.upload.addEventListener("progress", (e)=>{
            const delta = e.loaded - lastProgress;
            lastProgress += delta;
            opts.onProgress(delta);
        });
        xhr.send(opts.chunk);
        // Cleanup function that runs on interruption
        return Micro.sync(()=>xhr.abort());
    });

const uploadPresignedPostWithProgress = (file, presigned, opts)=>Micro.async((resume)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("POST", presigned.url);
        xhr.setRequestHeader("Accept", "application/xml");
        xhr.upload.addEventListener("progress", ({ loaded, total })=>{
            opts.onUploadProgress?.({
                file: file.name,
                progress: loaded / total * 100
            });
        });
        xhr.addEventListener("load", ()=>resume(xhr.status >= 200 && xhr.status < 300 ? Micro.succeed(null) : opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: null,
                fileName: file.name,
                storageProviderError: xhr.responseText
            })));
        xhr.addEventListener("error", ()=>resume(opts.reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: null,
                fileName: file.name
            })));
        const formData = new FormData();
        Object.entries(presigned.fields).forEach(([k, v])=>formData.append(k, v));
        formData.append("file", file); // File data **MUST GO LAST**
        xhr.send(formData);
        return Micro.sync(()=>{
            xhr.abort();
        });
    });

const maybeParseResponseXML = (maybeXml)=>{
    const codeMatch = maybeXml.match(/<Code>(.*?)<\/Code>/s);
    const messageMatch = maybeXml.match(/<Message>(.*?)<\/Message>/s);
    const code = codeMatch?.[1];
    const message = messageMatch?.[1];
    if (!code || !message) return null;
    return {
        code: s3CodeToUploadThingCode[code] ?? DEFAULT_ERROR_CODE,
        message
    };
};
/**
 * Map S3 error codes to UploadThing error codes
 *
 * This is a subset of the S3 error codes, based on what seemed most likely to
 * occur in uploadthing. For a full list of S3 error codes, see:
 * https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html
 */ const DEFAULT_ERROR_CODE = "UPLOAD_FAILED";
const s3CodeToUploadThingCode = {
    AccessDenied: "FORBIDDEN",
    EntityTooSmall: "TOO_SMALL",
    EntityTooLarge: "TOO_LARGE",
    ExpiredToken: "FORBIDDEN",
    IncorrectNumberOfFilesInPostRequest: "TOO_MANY_FILES",
    InternalError: "INTERNAL_SERVER_ERROR",
    KeyTooLongError: "KEY_TOO_LONG",
    MaxMessageLengthExceeded: "TOO_LARGE"
};

const createAPIRequestUrl = (config)=>{
    const url = new URL(config.url);
    const queryParams = new URLSearchParams(url.search);
    queryParams.set("actionType", config.actionType);
    queryParams.set("slug", config.slug);
    url.search = queryParams.toString();
    return url;
};
/**
 * Creates a "client" for reporting events to the UploadThing server via the user's API endpoint.
 * Events are handled in "./handler.ts starting at L112"
 */ const createUTReporter = (cfg)=>(type, payload)=>Micro.gen(function*() {
            const url = createAPIRequestUrl({
                url: cfg.url,
                slug: cfg.endpoint,
                actionType: type
            });
            let headers = typeof cfg.headers === "function" ? cfg.headers() : cfg.headers;
            if (headers instanceof Promise) {
                headers = yield* Micro.promise(()=>headers);
            }
            const response = yield* fetchEff(url, {
                method: "POST",
                body: JSON.stringify(payload),
                headers: {
                    "Content-Type": "application/json",
                    "x-uploadthing-package": cfg.package,
                    "x-uploadthing-version": version$1,
                    ...headers
                }
            }).pipe(Micro.andThen(parseResponseJson), /**
         * We don't _need_ to validate the response here, just cast it for now.
         * As of now, @effect/schema includes quite a few bytes we cut out by this...
         * We have "strong typing" on the backend that ensures the shape should match.
         */ Micro.map(unsafeCoerce), Micro.catchTag("FetchError", (e)=>Micro.fail(new UploadThingError({
                    code: "INTERNAL_CLIENT_ERROR",
                    message: `Failed to report event "${type}" to UploadThing server`,
                    cause: e
                }))), Micro.catchTag("BadRequestError", (e)=>Micro.fail(new UploadThingError({
                    code: getErrorTypeFromStatusCode(e.status),
                    message: e.getMessage(),
                    cause: e.json
                }))), Micro.catchTag("InvalidJson", (e)=>Micro.fail(new UploadThingError({
                    code: "INTERNAL_CLIENT_ERROR",
                    message: "Failed to parse response from UploadThing server",
                    cause: e
                }))));
            switch(type){
                case "failure":
                    {
                        // why isn't this narrowed automatically?
                        const p = payload;
                        const parsed = maybeParseResponseXML(p.storageProviderError ?? "");
                        if (parsed?.message) {
                            return yield* new UploadThingError({
                                code: parsed.code,
                                message: parsed.message
                            });
                        } else {
                            return yield* new UploadThingError({
                                code: "UPLOAD_FAILED",
                                message: `Failed to upload file ${p.fileName} to S3`,
                                cause: p.storageProviderError
                            });
                        }
                    }
            }
            return response;
        });

const version = version$1;
/**
 * Validate that a file is of a valid type given a route config
 * @public
 */ const isValidFileType = (file, routeConfig)=>Micro.runSync(getTypeFromFileName(file.name, objectKeys(routeConfig)).pipe(Micro.map((type)=>file.type.includes(type)), Micro.orElseSucceed(()=>false)));
/**
 * Validate that a file is of a valid size given a route config
 * @public
 */ const isValidFileSize = (file, routeConfig)=>Micro.runSync(getTypeFromFileName(file.name, objectKeys(routeConfig)).pipe(Micro.flatMap((type)=>fileSizeToBytes(routeConfig[type].maxFileSize)), Micro.map((maxFileSize)=>file.size <= maxFileSize), Micro.orElseSucceed(()=>false)));
/**
 * Generate a typed uploader for a given FileRouter
 * @public
 */ const genUploader = (initOpts)=>{
    return (endpoint, opts)=>uploadFilesInternal(endpoint, {
            ...opts,
            url: resolveMaybeUrlArg(initOpts?.url),
            package: initOpts.package,
            // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access
            input: opts.input
        }).pipe(Micro.provideService(FetchContext, {
            fetch: globalThis.fetch.bind(globalThis),
            baseHeaders: {
                "x-uploadthing-version": version$1,
                "x-uploadthing-api-key": undefined,
                "x-uploadthing-fe-package": initOpts.package,
                "x-uploadthing-be-adapter": undefined
            }
        }), (e)=>Micro.runPromiseExit(e, opts.signal ? {
                signal: opts.signal
            } : {})).then((exit)=>{
            if (exit._tag === "Right") {
                return exit.right;
            } else if (exit.left._tag === "Interrupt") {
                throw new UploadAbortedError();
            }
            throw Micro.causeSquash(exit.left);
        });
};
const uploadFilesInternal = (endpoint, opts)=>{
    // classic service right here
    const reportEventToUT = createUTReporter({
        endpoint: String(endpoint),
        package: opts.package,
        url: resolveMaybeUrlArg(opts.url),
        headers: opts.headers
    });
    return reportEventToUT("upload", {
        input: "input" in opts ? opts.input : null,
        files: opts.files.map((f)=>({
                name: f.name,
                size: f.size,
                type: f.type
            }))
    }).pipe(Micro.flatMap((responses)=>Micro.forEach(responses, (presigned)=>uploadFile(String(endpoint), {
                ...opts,
                reportEventToUT
            }, presigned).pipe(Micro.onInterrupt(reportEventToUT("failure", {
                fileKey: presigned.key,
                uploadId: "uploadId" in presigned ? presigned.uploadId : null,
                fileName: presigned.fileName
            }).pipe(Micro.ignore))), {
            concurrency: 6
        })));
};
const isPollingResponse = (input)=>{
    if (!isObject(input)) return false;
    if (input.status === "done") return "callbackData" in input;
    return input.status === "still waiting";
};
const isPollingDone = (input)=>{
    return input.status === "done";
};
const uploadFile = (slug, opts, presigned)=>Arr.findFirst(opts.files, (file)=>file.name === presigned.fileName).pipe(Micro.fromOption, Micro.mapError(()=>{
        // eslint-disable-next-line no-console
        console.error("No file found for presigned URL", presigned);
        return new UploadThingError({
            code: "NOT_FOUND",
            message: "No file found for presigned URL",
            cause: `Expected file with name ${presigned.fileName} but got '${opts.files.join(",")}'`
        });
    }), Micro.tap((file)=>opts.onUploadBegin?.({
            file: file.name
        })), Micro.tap((file)=>"urls" in presigned ? uploadMultipartWithProgress(file, presigned, opts) : uploadPresignedPostWithProgress(file, presigned, opts)), Micro.zip(fetchEff(presigned.pollingUrl, {
        headers: {
            authorization: presigned.pollingJwt
        }
    }).pipe(Micro.flatMap(parseResponseJson), Micro.catchTag("BadRequestError", (e)=>Micro.fail(new UploadThingError({
            code: getErrorTypeFromStatusCode(e.status),
            message: e.message,
            cause: e
        }))), Micro.filterOrFailCause(isPollingResponse, (_)=>Micro.causeDie("received a non PollingResponse from the polling endpoint")), Micro.filterOrFail(isPollingDone, ()=>new RetryError()), Micro.map(({ callbackData })=>callbackData), Micro.retry({
        while: (res)=>res._tag === "RetryError",
        schedule: exponentialDelay()
    }), Micro.when(()=>!opts.skipPolling), Micro.map(Option.getOrNull), Micro.map(unsafeCoerce))), Micro.map(([file, serverData])=>({
            name: file.name,
            size: file.size,
            key: presigned.key,
            serverData,
            url: presigned.fileUrl,
            appUrl: presigned.appUrl,
            customId: presigned.customId,
            type: file.type
        })));

export { genUploader, isValidFileSize, isValidFileType, version };
